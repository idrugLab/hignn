{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import Random\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.BRICS import FindBRICSBonds\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit import RDLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# attentive_fp fashion featurization\n",
    "# -------------------------------------\n",
    "def onehot_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(\n",
    "            x, allowable_set))\n",
    "    return [x == s for s in allowable_set]\n",
    "\n",
    "\n",
    "def onehot_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return [x == s for s in allowable_set]\n",
    "\n",
    "\n",
    "def atom_attr(mol, explicit_H=False, use_chirality=True, pharmaco=True, scaffold=True):\n",
    "    if pharmaco:\n",
    "        mol = tag_pharmacophore(mol)\n",
    "    if scaffold:\n",
    "        mol = tag_scaffold(mol)\n",
    "\n",
    "    feat = []\n",
    "    for i, atom in enumerate(mol.GetAtoms()):\n",
    "        results = onehot_encoding_unk(\n",
    "            atom.GetSymbol(),\n",
    "            ['B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br', 'Te', 'I', 'At', 'other'\n",
    "             ]) + onehot_encoding_unk(atom.GetDegree(),\n",
    "                                      [0, 1, 2, 3, 4, 5, 'other']) + \\\n",
    "                  [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
    "                  onehot_encoding_unk(atom.GetHybridization(), [\n",
    "                      Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                      Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D,\n",
    "                      Chem.rdchem.HybridizationType.SP3D2, 'other'\n",
    "                  ]) + [atom.GetIsAromatic()]\n",
    "        if not explicit_H:\n",
    "            results = results + onehot_encoding_unk(atom.GetTotalNumHs(),\n",
    "                                                    [0, 1, 2, 3, 4])\n",
    "        if use_chirality:\n",
    "            try:\n",
    "                results = results + onehot_encoding_unk(\n",
    "                    atom.GetProp('_CIPCode'),\n",
    "                    ['R', 'S']) + [atom.HasProp('_ChiralityPossible')]\n",
    "            # print(one_of_k_encoding_unk(atom.GetProp('_CIPCode'), ['R', 'S']) + [atom.HasProp('_ChiralityPossible')])\n",
    "            except:\n",
    "                results = results + [0, 0] + [atom.HasProp('_ChiralityPossible')]\n",
    "        if pharmaco:\n",
    "            results = results + [int(atom.GetProp('Hbond_donor'))] + [int(atom.GetProp('Hbond_acceptor'))] + \\\n",
    "                      [int(atom.GetProp('Basic'))] + [int(atom.GetProp('Acid'))] + \\\n",
    "                      [int(atom.GetProp('Halogen'))]\n",
    "        if scaffold:\n",
    "            results = results + [int(atom.GetProp('Scaffold'))]\n",
    "        feat.append(results)\n",
    "\n",
    "    return np.array(feat)\n",
    "\n",
    "\n",
    "def bond_attr(mol, use_chirality=True):\n",
    "    feat = []\n",
    "    index = []\n",
    "    n = mol.GetNumAtoms()\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                bond = mol.GetBondBetweenAtoms(i, j)\n",
    "                if bond is not None:\n",
    "                    bt = bond.GetBondType()\n",
    "                    bond_feats = [\n",
    "                        bt == Chem.rdchem.BondType.SINGLE, bt == Chem.rdchem.BondType.DOUBLE,\n",
    "                        bt == Chem.rdchem.BondType.TRIPLE, bt == Chem.rdchem.BondType.AROMATIC,\n",
    "                        bond.GetIsConjugated(),\n",
    "                        bond.IsInRing()\n",
    "                    ]\n",
    "                    if use_chirality:\n",
    "                        bond_feats = bond_feats + onehot_encoding_unk(\n",
    "                            str(bond.GetStereo()),\n",
    "                            [\"STEREONONE\", \"STEREOANY\", \"STEREOZ\", \"STEREOE\"])\n",
    "                    feat.append(bond_feats)\n",
    "                    index.append([i, j])\n",
    "\n",
    "    return np.array(index), np.array(feat)\n",
    "\n",
    "\n",
    "def bond_break(mol):\n",
    "    results = np.array(sorted(list(FindBRICSBonds(mol))), dtype=np.long)\n",
    "\n",
    "    if results.size == 0:\n",
    "        cluster_idx = []\n",
    "        Chem.rdmolops.GetMolFrags(mol, asMols=True, frags=cluster_idx)\n",
    "        fra_edge_index, fra_edge_attr = bond_attr(mol)\n",
    "\n",
    "    else:\n",
    "        bond_to_break = results[:, 0, :]\n",
    "        bond_to_break = bond_to_break.tolist()\n",
    "        with Chem.RWMol(mol) as rwmol:\n",
    "            for i in bond_to_break:\n",
    "                rwmol.RemoveBond(*i)\n",
    "        rwmol = rwmol.GetMol()\n",
    "        cluster_idx = []\n",
    "        Chem.rdmolops.GetMolFrags(rwmol, asMols=True, sanitizeFrags=False, frags=cluster_idx)\n",
    "        fra_edge_index, fra_edge_attr = bond_attr(rwmol)\n",
    "        cluster_idx = torch.LongTensor(cluster_idx)\n",
    "\n",
    "    return fra_edge_index, fra_edge_attr, cluster_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# Scaffold and pharmacophore information utils\n",
    "# ---------------------------------------------\n",
    "# tag pharmoco features to each atom\n",
    "fun_smarts = {\n",
    "        'Hbond_donor': '[$([N;!H0;v3,v4&+1]),$([O,S;H1;+0]),n&H1&+0]',\n",
    "        'Hbond_acceptor': '[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),$([O,S;H0;v2]),$([O,S;-]),$([N;v3;!$(N-*=[O,N,P,S])]),n&X2&H0&+0,$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]',\n",
    "        'Basic': '[#7;+,$([N;H2&+0][$([C,a]);!$([C,a](=O))]),$([N;H1&+0]([$([C,a]);!$([C,a](=O))])[$([C,a]);!$([C,a](=O))]),$([N;H0&+0]([C;!$(C(=O))])([C;!$(C(=O))])[C;!$(C(=O))]),$([n;X2;+0;-0])]',\n",
    "        'Acid': '[C,S](=[O,S,P])-[O;H1,-1]',\n",
    "        'Halogen': '[F,Cl,Br,I]'\n",
    "        }\n",
    "FunQuery = dict([(pharmaco, Chem.MolFromSmarts(s)) for (pharmaco, s) in fun_smarts.items()])\n",
    "\n",
    "\n",
    "def tag_pharmacophore(mol):\n",
    "    for fungrp, qmol in FunQuery.items():\n",
    "        matches = mol.GetSubstructMatches(qmol)\n",
    "        match_idxes = []\n",
    "        for mat in matches:\n",
    "            match_idxes.extend(mat)\n",
    "        for i, atom in enumerate(mol.GetAtoms()):\n",
    "            tag = '1' if i in match_idxes else '0'\n",
    "            atom.SetProp(fungrp, tag)\n",
    "    return mol\n",
    "\n",
    "\n",
    "# tag scaffold information to each atom\n",
    "def tag_scaffold(mol):\n",
    "    core = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    match_idxes = mol.GetSubstructMatch(core)\n",
    "    for i, atom in enumerate(mol.GetAtoms()):\n",
    "        tag = '1' if i in match_idxes else '0'\n",
    "        atom.SetProp('Scaffold', tag)\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# data and dataset\n",
    "# ---------------------------------\n",
    "class MolData(Data):\n",
    "    def __init__(self, fra_edge_index=None, fra_edge_attr=None, cluster_index=None, **kwargs):\n",
    "        super(MolData, self).__init__(**kwargs)\n",
    "        self.cluster_index = cluster_index\n",
    "        self.fra_edge_index = fra_edge_index\n",
    "        self.fra_edge_attr = fra_edge_attr\n",
    "\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'cluster_index':\n",
    "            return int(self.cluster_index.max()) + 1\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)\n",
    "\n",
    "\n",
    "class MolDataset(InMemoryDataset):\n",
    "\n",
    "    def __init__(self, root, dataset, task_type, tasks, logger=None,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "\n",
    "        self.tasks = tasks\n",
    "        self.dataset = dataset\n",
    "        self.task_type = task_type\n",
    "\n",
    "        super(MolDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['{}.csv'.format(self.dataset)]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['{}.pt'.format(self.dataset)]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        df = pd.read_csv(self.raw_paths[0])\n",
    "        smilesList = df.smiles.values\n",
    "        print(f'number of all smiles: {len(smilesList)}')\n",
    "        remained_smiles = []\n",
    "        canonical_smiles_list = []\n",
    "        for smiles in smilesList:\n",
    "            try:\n",
    "                canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "                remained_smiles.append(smiles)\n",
    "            except:\n",
    "                print(f'not successfully processed smiles: {smiles}')\n",
    "                pass\n",
    "        print(f'number of successfully processed smiles: {len(remained_smiles)}')\n",
    "\n",
    "        df = df[df[\"smiles\"].isin(remained_smiles)].reset_index()\n",
    "        target = df[self.tasks].values\n",
    "        smilesList = df.smiles.values\n",
    "        data_list = []\n",
    "\n",
    "        for i, smi in enumerate(tqdm(smilesList)):\n",
    "\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            data = self.mol2graph(mol)\n",
    "\n",
    "            if data is not None:\n",
    "                label = target[i]\n",
    "                label[np.isnan(label)] = 666\n",
    "                data.y = torch.LongTensor([label])\n",
    "                if self.task_type == 'regression':\n",
    "                    data.y = torch.FloatTensor([label])\n",
    "                data_list.append(data)\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def mol2graph(self, mol):\n",
    "        smiles = Chem.MolToSmiles(mol)\n",
    "        if mol is None: return None\n",
    "        node_attr = atom_attr(mol)\n",
    "        edge_index, edge_attr = bond_attr(mol)\n",
    "        fra_edge_index, fra_edge_attr, cluster_index = bond_break(mol)\n",
    "        data = MolData(\n",
    "            x=torch.FloatTensor(node_attr),\n",
    "            edge_index=torch.LongTensor(edge_index).t(),\n",
    "            edge_attr=torch.FloatTensor(edge_attr),\n",
    "            fra_edge_index=torch.LongTensor(fra_edge_index).t(),\n",
    "            fra_edge_attr=torch.FloatTensor(fra_edge_attr),\n",
    "            cluster_index=torch.LongTensor(cluster_index),\n",
    "            y=None,\n",
    "            smiles=smiles,\n",
    "        )\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, Parameter, Bilinear\n",
    "\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.nn import global_add_pool, GATConv\n",
    "from torch_geometric.utils import softmax\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import glorot, reset, zeros\n",
    "from torch_geometric.nn.pool.pool import pool_batch\n",
    "from torch_geometric.nn.pool.consecutive import consecutive_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Attention layers\n",
    "# ---------------------------------------\n",
    "class FeatureAttention(nn.Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super().__init__()\n",
    "        self.mlp = Sequential(\n",
    "            Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(channels // reduction, channels, bias=False),\n",
    "        )\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.mlp)\n",
    "\n",
    "    def forward(self, x, batch, size=None):\n",
    "        max_result = scatter(x, batch, dim=0, dim_size=size, reduce='max')\n",
    "        sum_result = scatter(x, batch, dim=0, dim_size=size, reduce='sum')\n",
    "        max_out = self.mlp(max_result)\n",
    "        sum_out = self.mlp(sum_result)\n",
    "        y = torch.sigmoid(max_out + sum_out)\n",
    "        y = y[batch]\n",
    "        return x * y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GATEConv(MessagePassing):\n",
    "    def __init__(self, in_channels, out_channels, heads=1, concat=True, negative_slope=0.01,\n",
    "                 dropout=0.0, edge_dim=None, bias=True, **kwargs,):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super().__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.heads = heads\n",
    "        self.concat = concat\n",
    "        self.negative_slope = negative_slope\n",
    "        self.dropout = dropout\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        if isinstance(in_channels, int):\n",
    "            self.lin_src = Linear(in_channels, heads * out_channels, bias=False)\n",
    "            self.lin_dst = self.lin_src\n",
    "        else:\n",
    "            self.lin_src = Linear(in_channels[0], heads * out_channels, False)\n",
    "            self.lin_dst = Linear(in_channels[1], heads * out_channels, False)\n",
    "\n",
    "        self.att_src = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        self.att_dst = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "\n",
    "        if edge_dim is not None:\n",
    "            self.lin_edge = Linear(edge_dim, heads * out_channels, bias=False)\n",
    "            self.att_edge = Parameter(torch.Tensor(1, heads, out_channels))\n",
    "        else:\n",
    "            self.lin_edge = None\n",
    "            self.register_parameter('att_edge', None)\n",
    "\n",
    "        if bias and concat:\n",
    "            self.bias = Parameter(torch.Tensor(heads * out_channels))\n",
    "        elif bias and not concat:\n",
    "            self.bias = Parameter(torch.Tensor(out_channels))\n",
    "        else:\n",
    "            self.register_parameter('bias', None)\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        self.lin_src.reset_parameters()\n",
    "        self.lin_dst.reset_parameters()\n",
    "        if self.lin_edge is not None:\n",
    "            self.lin_edge.reset_parameters()\n",
    "        glorot(self.att_src)\n",
    "        glorot(self.att_dst)\n",
    "        glorot(self.att_edge)\n",
    "        zeros(self.bias)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr, size=None, return_attention_weights=None):\n",
    "        H, C = self.heads, self.out_channels\n",
    "\n",
    "        x_src = x_dst = self.lin_src(x).view(-1, H, C)\n",
    "        x = (x_src, x_dst)\n",
    "\n",
    "        alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
    "        alpha_dst = None if x_dst is None else (x_dst * self.att_dst).sum(-1)\n",
    "        alpha = (alpha_src, alpha_dst)\n",
    "\n",
    "        out = self.propagate(edge_index, x=x, alpha=alpha, edge_attr=edge_attr,\n",
    "                             size=size)\n",
    "\n",
    "        alpha = self._alpha\n",
    "        assert alpha is not None\n",
    "        self._alpha = None\n",
    "\n",
    "        if self.concat:\n",
    "            out = out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "\n",
    "        if isinstance(return_attention_weights, bool):\n",
    "            return out, (edge_index, alpha)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def message(self, x_j, alpha_j, alpha_i, edge_attr, index, ptr, size_i):\n",
    "        alpha = alpha_j if alpha_i is None else alpha_j + alpha_i\n",
    "\n",
    "        if edge_attr is not None:\n",
    "            if edge_attr.dim() == 1:\n",
    "                edge_attr = edge_attr.view(-1, 1)\n",
    "            assert self.lin_edge is not None\n",
    "            edge_attr = self.lin_edge(edge_attr)\n",
    "            edge_attr = edge_attr.view(-1, self.heads, self.out_channels)\n",
    "            alpha_edge = (edge_attr * self.att_edge).sum(dim=-1)\n",
    "            alpha = alpha + alpha_edge\n",
    "\n",
    "        alpha = F.leaky_relu(alpha, self.negative_slope)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha  # Save for later use.\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        return x_j * alpha.unsqueeze(-1)\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}({self.in_channels}, '\n",
    "                f'{self.out_channels}, heads={self.heads})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# HiGNN backbone\n",
    "# ---------------------------------------\n",
    "class HiGNN(torch.nn.Module):\n",
    "    \"\"\"Hierarchical informative graph neural network for molecular representation.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim, num_layers,\n",
    "                 heads, dropout, f_att=False, r=4, brics=True, cl=False):\n",
    "        super(HiGNN, self).__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.f_att = f_att\n",
    "        self.brics = brics\n",
    "        self.cl = cl\n",
    "\n",
    "        # atom feature transformation\n",
    "        self.lin_a = Linear(in_channels, hidden_channels)\n",
    "        self.lin_b = Linear(edge_dim, hidden_channels)\n",
    "\n",
    "        # convs block\n",
    "        self.atom_convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = GATEConv(hidden_channels, int(hidden_channels/heads), heads=heads, negative_slope=0.01,\n",
    "                            dropout=dropout, edge_dim=hidden_channels)\n",
    "            self.atom_convs.append(conv)\n",
    "\n",
    "        self.lin_gate = Linear(3 * hidden_channels, hidden_channels)\n",
    "\n",
    "        if self.f_att:\n",
    "            self.feature_att = FeatureAttention(channels=hidden_channels, reduction=r)\n",
    "\n",
    "        if self.brics:\n",
    "            # mol-fra attention\n",
    "            self.cross_att = GATConv(hidden_channels, hidden_channels, heads=4,\n",
    "                                     dropout=dropout, add_self_loops=False,\n",
    "                                     negative_slope=0.01, concat=False)\n",
    "\n",
    "        if self.brics:\n",
    "            self.out = Linear(2 * hidden_channels, out_channels)\n",
    "        else:\n",
    "            self.out = Linear(hidden_channels, out_channels)\n",
    "\n",
    "        if self.cl:\n",
    "            self.lin_project = Linear(hidden_channels, int(hidden_channels/2))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "\n",
    "        self.lin_a.reset_parameters()\n",
    "        self.lin_b.reset_parameters()\n",
    "\n",
    "        for conv in self.atom_convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "        self.lin_gate.reset_parameters()\n",
    "\n",
    "        if self.f_att:\n",
    "            self.feature_att.reset_parameters()\n",
    "\n",
    "        if self.brics:\n",
    "            self.cross_att.reset_parameters()\n",
    "\n",
    "        self.out.reset_parameters()\n",
    "\n",
    "        if self.cl:\n",
    "            self.lin_project.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        # get mol input\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        batch = data.batch\n",
    "\n",
    "        x = F.relu(self.lin_a(x))  # (N, 46) -> (N, hidden_channels)\n",
    "        edge_attr = F.relu(self.lin_b(edge_attr))  # (N, 10) -> (N, hidden_channels)\n",
    "\n",
    "        alphas = []\n",
    "        # mol conv block\n",
    "        for i in range(0, self.num_layers):\n",
    "            h, (_, alpha) = self.atom_convs[i](x, edge_index, edge_attr, return_attention_weights=True)\n",
    "            alphas.append(alpha)\n",
    "            h = F.relu(h)\n",
    "            beta = self.lin_gate(torch.cat([x, h, x - h], 1)).sigmoid()\n",
    "            x = beta * x + (1 - beta) * h\n",
    "            if self.f_att:\n",
    "                x = self.feature_att(x, batch)\n",
    "\n",
    "        mol_vec = global_add_pool(x, batch).relu_()\n",
    "\n",
    "        if self.brics:\n",
    "            # get fragment input\n",
    "            fra_x = data.x\n",
    "            fra_edge_index = data.fra_edge_index\n",
    "            fra_edge_attr = data.fra_edge_attr\n",
    "            cluster = data.cluster_index\n",
    "\n",
    "            fra_x = F.relu(self.lin_a(fra_x))  # (N, 46) -> (N, hidden_channels)\n",
    "            fra_edge_attr = F.leaky_relu_(self.lin_b(fra_edge_attr))  # (N, 10) -> (N, hidden_channels)\n",
    "\n",
    "            # fragment convs block\n",
    "            for i in range(0, self.num_layers):\n",
    "                fra_h = F.relu(self.atom_convs[i](fra_x, fra_edge_index, fra_edge_attr))\n",
    "                beta = self.lin_gate(torch.cat([fra_x, fra_h, fra_x - fra_h], 1)).sigmoid()\n",
    "                fra_x = beta * fra_x + (1 - beta) * fra_h\n",
    "                if self.f_att:\n",
    "                    fra_x = self.feature_att(fra_x, cluster)\n",
    "\n",
    "            fra_x = global_add_pool(fra_x, cluster).relu_()\n",
    "\n",
    "            # get fragment batch\n",
    "            cluster, perm = consecutive_cluster(cluster)\n",
    "            fra_batch = pool_batch(perm, data.batch)\n",
    "\n",
    "            # molecule-fragment attention\n",
    "            row = torch.arange(fra_batch.size(0), device=batch.device)\n",
    "            mol_fra_index = torch.stack([row, fra_batch], dim=0)\n",
    "            fra_vec = self.cross_att((fra_x, mol_vec), mol_fra_index)\n",
    "            fra_vec = fra_vec.relu()\n",
    "\n",
    "            vectors_concat = list()\n",
    "            vectors_concat.append(mol_vec)\n",
    "            vectors_concat.append(fra_vec)\n",
    "\n",
    "            out = torch.cat(vectors_concat, 1)\n",
    "\n",
    "            # molecule-fragment contrastive\n",
    "            if self.cl:\n",
    "                out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "                return self.out(out), self.lin_project(mol_vec).relu_(), self.lin_project(fra_vec).relu_()\n",
    "            else:\n",
    "                out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "                return self.out(out), alphas\n",
    "\n",
    "        else:\n",
    "            assert self.cl is False\n",
    "            out = F.dropout(mol_vec, p=self.dropout, training=self.training)\n",
    "            return self.out(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_result(model):\n",
    "    best_ckpt_path = 'E:/3-Code/Jupternote book/HiGNN_Vis/tox21_best_ckpt_gat.pth'\n",
    "    ckpt = torch.load(best_ckpt_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HiGNN(\n",
      "  (lin_a): Linear(in_features=46, out_features=256, bias=True)\n",
      "  (lin_b): Linear(in_features=10, out_features=256, bias=True)\n",
      "  (atom_convs): ModuleList(\n",
      "    (0): GATEConv(256, 128, heads=2)\n",
      "    (1): GATEConv(256, 128, heads=2)\n",
      "  )\n",
      "  (lin_gate): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (feature_att): FeatureAttention(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=64, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=64, out_features=256, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (cross_att): GATConv(256, 256, heads=4)\n",
      "  (out): Linear(in_features=512, out_features=24, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Build HiGNN \n",
    "# ---------------------------------------\n",
    "model = HiGNN(in_channels=46,\n",
    "              hidden_channels=256,\n",
    "              out_channels=24,\n",
    "              edge_dim=10,\n",
    "              num_layers=2,\n",
    "              dropout=0.2,\n",
    "              heads=2,\n",
    "              f_att=True,\n",
    "              r=4,\n",
    "              brics=True,\n",
    "              cl=False)\n",
    "\n",
    "model = load_best_result(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def get_header(path):\n",
    "    with open(path) as f:\n",
    "        header = next(csv.reader(f))\n",
    "\n",
    "    return header\n",
    "\n",
    "\n",
    "def get_task_names(path, use_compound_names=False):\n",
    "    index = 2 if use_compound_names else 1\n",
    "    task_names = get_header(path)[index:]\n",
    "\n",
    "    return task_names\n",
    "\n",
    "task_names = get_task_names('E:/3-Code/Jupternote book/HiGNN_Vis/raw/tox21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7831\n"
     ]
    }
   ],
   "source": [
    "path = 'E:/3-Code/Jupternote book/HiGNN_Vis'\n",
    "dataset = 'tox21'\n",
    "task_type = 'classification'\n",
    "tasks = task_names\n",
    "tox21 = MolDataset(root=path, dataset=dataset, task_type=task_type, tasks=tasks)\n",
    "print(len(tox21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 2021\n",
    "random = Random(seed)\n",
    "indices = list(range(len(tox21)))\n",
    "random.seed(seed)\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_size = int(0.8 * len(tox21))\n",
    "val_size = int(0.1 * len(tox21))\n",
    "test_size = len(tox21) - train_size - val_size\n",
    "\n",
    "trn_id, val_id, test_id = indices[:train_size], \\\n",
    "                          indices[train_size:(train_size + val_size)], \\\n",
    "                          indices[(train_size + val_size):]\n",
    "len(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_test = tox21[test_id[:50]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[957], cluster_index=[957], edge_attr=[1990, 10], edge_index=[2, 1990], fra_edge_attr=[1748, 10], fra_edge_index=[2, 1748], ptr=[51], smiles=[50], x=[957, 46], y=[50, 12])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader =  DataLoader(tox21_test, batch_size=50)\n",
    "iter_ = iter(loader)\n",
    "batch = next(iter_)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # 关闭dropout\n",
    "output = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.1116,  0.4009,  0.8997,  ...,  4.0205, -3.0725,  3.5760],\n",
       "         [ 0.3558, -0.2392, -0.0683,  ...,  1.1661, -1.1388,  1.2222],\n",
       "         [ 0.6047, -1.1121,  2.4211,  ..., -1.2846,  3.4469, -3.5935],\n",
       "         ...,\n",
       "         [-0.1408,  0.1045,  0.9280,  ...,  1.4508, -0.6292,  0.3815],\n",
       "         [ 1.0401, -1.6671,  0.8305,  ..., -1.3361,  0.4627, -0.5751],\n",
       "         [ 1.2003, -2.2068,  1.9652,  ...,  0.2370,  2.6598, -3.0875]],\n",
       "        grad_fn=<AddmmBackward>),\n",
       " [tensor([[6.8203e-01, 6.6608e-14],\n",
       "          [1.0000e+00, 1.0000e+00],\n",
       "          [5.0000e-01, 5.0000e-01],\n",
       "          ...,\n",
       "          [4.9811e-01, 9.1981e-05],\n",
       "          [1.0000e+00, 1.0000e+00],\n",
       "          [4.9858e-01, 2.9452e-01]], grad_fn=<DivBackward0>),\n",
       "  tensor([[1.0000, 1.0000],\n",
       "          [1.0000, 1.0000],\n",
       "          [0.6900, 0.5120],\n",
       "          ...,\n",
       "          [0.0129, 0.0500],\n",
       "          [1.0000, 1.0000],\n",
       "          [0.0040, 0.0272]], grad_fn=<DifferentiableGraphBackward>)])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "att = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = att[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "last = last.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.999997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.899987e-01</td>\n",
       "      <td>0.511965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.721843e-02</td>\n",
       "      <td>0.001054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.671779e-10</td>\n",
       "      <td>0.000001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>3.028517e-01</td>\n",
       "      <td>0.285491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>9.960065e-01</td>\n",
       "      <td>0.972841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>1.292867e-02</td>\n",
       "      <td>0.049978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>3.993511e-03</td>\n",
       "      <td>0.027159</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1990 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0         1\n",
       "0     1.000000e+00  0.999997\n",
       "1     1.000000e+00  1.000000\n",
       "2     6.899987e-01  0.511965\n",
       "3     1.721843e-02  0.001054\n",
       "4     5.671779e-10  0.000001\n",
       "...            ...       ...\n",
       "1985  3.028517e-01  0.285491\n",
       "1986  9.960065e-01  0.972841\n",
       "1987  1.292867e-02  0.049978\n",
       "1988  1.000000e+00  1.000000\n",
       "1989  3.993511e-03  0.027159\n",
       "\n",
       "[1990 rows x 2 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('att_tox21_gat.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
