{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from random import Random\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Data, InMemoryDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem.BRICS import FindBRICSBonds\n",
    "from rdkit.Chem.Scaffolds import MurckoScaffold\n",
    "from rdkit import RDLogger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------------\n",
    "# attentive_fp fashion featurization\n",
    "# -------------------------------------\n",
    "def onehot_encoding(x, allowable_set):\n",
    "    if x not in allowable_set:\n",
    "        raise Exception(\"input {0} not in allowable set{1}:\".format(\n",
    "            x, allowable_set))\n",
    "    return [x == s for s in allowable_set]\n",
    "\n",
    "\n",
    "def onehot_encoding_unk(x, allowable_set):\n",
    "    \"\"\"Maps inputs not in the allowable set to the last element.\"\"\"\n",
    "    if x not in allowable_set:\n",
    "        x = allowable_set[-1]\n",
    "    return [x == s for s in allowable_set]\n",
    "\n",
    "\n",
    "def atom_attr(mol, explicit_H=False, use_chirality=True, pharmaco=True, scaffold=True):\n",
    "    if pharmaco:\n",
    "        mol = tag_pharmacophore(mol)\n",
    "    if scaffold:\n",
    "        mol = tag_scaffold(mol)\n",
    "\n",
    "    feat = []\n",
    "    for i, atom in enumerate(mol.GetAtoms()):\n",
    "        results = onehot_encoding_unk(\n",
    "            atom.GetSymbol(),\n",
    "            ['B', 'C', 'N', 'O', 'F', 'Si', 'P', 'S', 'Cl', 'As', 'Se', 'Br', 'Te', 'I', 'At', 'other'\n",
    "             ]) + onehot_encoding_unk(atom.GetDegree(),\n",
    "                                      [0, 1, 2, 3, 4, 5, 'other']) + \\\n",
    "                  [atom.GetFormalCharge(), atom.GetNumRadicalElectrons()] + \\\n",
    "                  onehot_encoding_unk(atom.GetHybridization(), [\n",
    "                      Chem.rdchem.HybridizationType.SP, Chem.rdchem.HybridizationType.SP2,\n",
    "                      Chem.rdchem.HybridizationType.SP3, Chem.rdchem.HybridizationType.SP3D,\n",
    "                      Chem.rdchem.HybridizationType.SP3D2, 'other'\n",
    "                  ]) + [atom.GetIsAromatic()]\n",
    "        if not explicit_H:\n",
    "            results = results + onehot_encoding_unk(atom.GetTotalNumHs(),\n",
    "                                                    [0, 1, 2, 3, 4])\n",
    "        if use_chirality:\n",
    "            try:\n",
    "                results = results + onehot_encoding_unk(\n",
    "                    atom.GetProp('_CIPCode'),\n",
    "                    ['R', 'S']) + [atom.HasProp('_ChiralityPossible')]\n",
    "            # print(one_of_k_encoding_unk(atom.GetProp('_CIPCode'), ['R', 'S']) + [atom.HasProp('_ChiralityPossible')])\n",
    "            except:\n",
    "                results = results + [0, 0] + [atom.HasProp('_ChiralityPossible')]\n",
    "        if pharmaco:\n",
    "            results = results + [int(atom.GetProp('Hbond_donor'))] + [int(atom.GetProp('Hbond_acceptor'))] + \\\n",
    "                      [int(atom.GetProp('Basic'))] + [int(atom.GetProp('Acid'))] + \\\n",
    "                      [int(atom.GetProp('Halogen'))]\n",
    "        if scaffold:\n",
    "            results = results + [int(atom.GetProp('Scaffold'))]\n",
    "        feat.append(results)\n",
    "\n",
    "    return np.array(feat)\n",
    "\n",
    "\n",
    "def bond_attr(mol, use_chirality=True):\n",
    "    feat = []\n",
    "    index = []\n",
    "    n = mol.GetNumAtoms()\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            if i != j:\n",
    "                bond = mol.GetBondBetweenAtoms(i, j)\n",
    "                if bond is not None:\n",
    "                    bt = bond.GetBondType()\n",
    "                    bond_feats = [\n",
    "                        bt == Chem.rdchem.BondType.SINGLE, bt == Chem.rdchem.BondType.DOUBLE,\n",
    "                        bt == Chem.rdchem.BondType.TRIPLE, bt == Chem.rdchem.BondType.AROMATIC,\n",
    "                        bond.GetIsConjugated(),\n",
    "                        bond.IsInRing()\n",
    "                    ]\n",
    "                    if use_chirality:\n",
    "                        bond_feats = bond_feats + onehot_encoding_unk(\n",
    "                            str(bond.GetStereo()),\n",
    "                            [\"STEREONONE\", \"STEREOANY\", \"STEREOZ\", \"STEREOE\"])\n",
    "                    feat.append(bond_feats)\n",
    "                    index.append([i, j])\n",
    "\n",
    "    return np.array(index), np.array(feat)\n",
    "\n",
    "\n",
    "def bond_break(mol):\n",
    "    results = np.array(sorted(list(FindBRICSBonds(mol))), dtype=np.long)\n",
    "\n",
    "    if results.size == 0:\n",
    "        cluster_idx = []\n",
    "        Chem.rdmolops.GetMolFrags(mol, asMols=True, frags=cluster_idx)\n",
    "        fra_edge_index, fra_edge_attr = bond_attr(mol)\n",
    "\n",
    "    else:\n",
    "        bond_to_break = results[:, 0, :]\n",
    "        bond_to_break = bond_to_break.tolist()\n",
    "        with Chem.RWMol(mol) as rwmol:\n",
    "            for i in bond_to_break:\n",
    "                rwmol.RemoveBond(*i)\n",
    "        rwmol = rwmol.GetMol()\n",
    "        cluster_idx = []\n",
    "        Chem.rdmolops.GetMolFrags(rwmol, asMols=True, sanitizeFrags=False, frags=cluster_idx)\n",
    "        fra_edge_index, fra_edge_attr = bond_attr(rwmol)\n",
    "        cluster_idx = torch.LongTensor(cluster_idx)\n",
    "\n",
    "    return fra_edge_index, fra_edge_attr, cluster_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------\n",
    "# Scaffold and pharmacophore information utils\n",
    "# ---------------------------------------------\n",
    "# tag pharmoco features to each atom\n",
    "fun_smarts = {\n",
    "        'Hbond_donor': '[$([N;!H0;v3,v4&+1]),$([O,S;H1;+0]),n&H1&+0]',\n",
    "        'Hbond_acceptor': '[$([O,S;H1;v2;!$(*-*=[O,N,P,S])]),$([O,S;H0;v2]),$([O,S;-]),$([N;v3;!$(N-*=[O,N,P,S])]),n&X2&H0&+0,$([o,s;+0;!$([o,s]:n);!$([o,s]:c:n)])]',\n",
    "        'Basic': '[#7;+,$([N;H2&+0][$([C,a]);!$([C,a](=O))]),$([N;H1&+0]([$([C,a]);!$([C,a](=O))])[$([C,a]);!$([C,a](=O))]),$([N;H0&+0]([C;!$(C(=O))])([C;!$(C(=O))])[C;!$(C(=O))]),$([n;X2;+0;-0])]',\n",
    "        'Acid': '[C,S](=[O,S,P])-[O;H1,-1]',\n",
    "        'Halogen': '[F,Cl,Br,I]'\n",
    "        }\n",
    "FunQuery = dict([(pharmaco, Chem.MolFromSmarts(s)) for (pharmaco, s) in fun_smarts.items()])\n",
    "\n",
    "\n",
    "def tag_pharmacophore(mol):\n",
    "    for fungrp, qmol in FunQuery.items():\n",
    "        matches = mol.GetSubstructMatches(qmol)\n",
    "        match_idxes = []\n",
    "        for mat in matches:\n",
    "            match_idxes.extend(mat)\n",
    "        for i, atom in enumerate(mol.GetAtoms()):\n",
    "            tag = '1' if i in match_idxes else '0'\n",
    "            atom.SetProp(fungrp, tag)\n",
    "    return mol\n",
    "\n",
    "\n",
    "# tag scaffold information to each atom\n",
    "def tag_scaffold(mol):\n",
    "    core = MurckoScaffold.GetScaffoldForMol(mol)\n",
    "    match_idxes = mol.GetSubstructMatch(core)\n",
    "    for i, atom in enumerate(mol.GetAtoms()):\n",
    "        tag = '1' if i in match_idxes else '0'\n",
    "        atom.SetProp('Scaffold', tag)\n",
    "    return mol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------\n",
    "# data and dataset\n",
    "# ---------------------------------\n",
    "class MolData(Data):\n",
    "    def __init__(self, fra_edge_index=None, fra_edge_attr=None, cluster_index=None, **kwargs):\n",
    "        super(MolData, self).__init__(**kwargs)\n",
    "        self.cluster_index = cluster_index\n",
    "        self.fra_edge_index = fra_edge_index\n",
    "        self.fra_edge_attr = fra_edge_attr\n",
    "\n",
    "    def __inc__(self, key, value, *args, **kwargs):\n",
    "        if key == 'cluster_index':\n",
    "            return int(self.cluster_index.max()) + 1\n",
    "        else:\n",
    "            return super().__inc__(key, value, *args, **kwargs)\n",
    "\n",
    "\n",
    "class MolDataset(InMemoryDataset):\n",
    "\n",
    "    def __init__(self, root, dataset, task_type, tasks, logger=None,\n",
    "                 transform=None, pre_transform=None, pre_filter=None):\n",
    "\n",
    "        self.tasks = tasks\n",
    "        self.dataset = dataset\n",
    "        self.task_type = task_type\n",
    "\n",
    "        super(MolDataset, self).__init__(root, transform, pre_transform, pre_filter)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return ['{}.csv'.format(self.dataset)]\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return ['{}.pt'.format(self.dataset)]\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        df = pd.read_csv(self.raw_paths[0])\n",
    "        smilesList = df.smiles.values\n",
    "        print(f'number of all smiles: {len(smilesList)}')\n",
    "        remained_smiles = []\n",
    "        canonical_smiles_list = []\n",
    "        for smiles in smilesList:\n",
    "            try:\n",
    "                canonical_smiles_list.append(Chem.MolToSmiles(Chem.MolFromSmiles(smiles), isomericSmiles=True))\n",
    "                remained_smiles.append(smiles)\n",
    "            except:\n",
    "                print(f'not successfully processed smiles: {smiles}')\n",
    "                pass\n",
    "        print(f'number of successfully processed smiles: {len(remained_smiles)}')\n",
    "\n",
    "        df = df[df[\"smiles\"].isin(remained_smiles)].reset_index()\n",
    "        target = df[self.tasks].values\n",
    "        smilesList = df.smiles.values\n",
    "        data_list = []\n",
    "\n",
    "        for i, smi in enumerate(tqdm(smilesList)):\n",
    "\n",
    "            mol = Chem.MolFromSmiles(smi)\n",
    "            data = self.mol2graph(mol)\n",
    "\n",
    "            if data is not None:\n",
    "                label = target[i]\n",
    "                label[np.isnan(label)] = 666\n",
    "                data.y = torch.LongTensor([label])\n",
    "                if self.task_type == 'regression':\n",
    "                    data.y = torch.FloatTensor([label])\n",
    "                data_list.append(data)\n",
    "\n",
    "        if self.pre_filter is not None:\n",
    "            data_list = [data for data in data_list if self.pre_filter(data)]\n",
    "        if self.pre_transform is not None:\n",
    "            data_list = [self.pre_transform(data) for data in data_list]\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n",
    "    def mol2graph(self, mol):\n",
    "        smiles = Chem.MolToSmiles(mol)\n",
    "        if mol is None: return None\n",
    "        node_attr = atom_attr(mol)\n",
    "        edge_index, edge_attr = bond_attr(mol)\n",
    "        fra_edge_index, fra_edge_attr, cluster_index = bond_break(mol)\n",
    "        data = MolData(\n",
    "            x=torch.FloatTensor(node_attr),\n",
    "            edge_index=torch.LongTensor(edge_index).t(),\n",
    "            edge_attr=torch.FloatTensor(edge_attr),\n",
    "            fra_edge_index=torch.LongTensor(fra_edge_index).t(),\n",
    "            fra_edge_attr=torch.FloatTensor(fra_edge_attr),\n",
    "            cluster_index=torch.LongTensor(cluster_index),\n",
    "            y=None,\n",
    "            smiles=smiles,\n",
    "        )\n",
    "        return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, Parameter, Bilinear\n",
    "\n",
    "from torch_scatter import scatter\n",
    "from torch_geometric.nn import global_add_pool, GATConv\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import glorot, reset\n",
    "from torch_geometric.nn.pool.pool import pool_batch\n",
    "from torch_geometric.nn.pool.consecutive import consecutive_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Attention layers\n",
    "# ---------------------------------------\n",
    "class FeatureAttention(nn.Module):\n",
    "    def __init__(self, channels, reduction):\n",
    "        super().__init__()\n",
    "        self.mlp = Sequential(\n",
    "            Linear(channels, channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            Linear(channels // reduction, channels, bias=False),\n",
    "        )\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        reset(self.mlp)\n",
    "\n",
    "    def forward(self, x, batch, size=None):\n",
    "        max_result = scatter(x, batch, dim=0, dim_size=size, reduce='max')\n",
    "        sum_result = scatter(x, batch, dim=0, dim_size=size, reduce='sum')\n",
    "        max_out = self.mlp(max_result)\n",
    "        sum_out = self.mlp(sum_result)\n",
    "        y = torch.sigmoid(max_out + sum_out)\n",
    "        y_ = y\n",
    "        y = y[batch]\n",
    "        return x * y, y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# Neural tensor networks conv\n",
    "# ---------------------------------------\n",
    "class NTNConv(MessagePassing):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, slices, dropout, edge_dim=None, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'add')\n",
    "        super(NTNConv, self).__init__(node_dim=0, **kwargs)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.slices = slices\n",
    "        self.dropout = dropout\n",
    "        self.edge_dim = edge_dim\n",
    "\n",
    "        self.weight_node = Parameter(torch.Tensor(in_channels,\n",
    "                                                  out_channels))\n",
    "        if edge_dim is not None:\n",
    "            self.weight_edge = Parameter(torch.Tensor(edge_dim,\n",
    "                                                      out_channels))\n",
    "        else:\n",
    "            self.weight_edge = self.register_parameter('weight_edge', None)\n",
    "\n",
    "        self.bilinear = Bilinear(out_channels, out_channels, slices, bias=False)\n",
    "\n",
    "        if self.edge_dim is not None:\n",
    "            self.linear = Linear(3 * out_channels, slices)\n",
    "        else:\n",
    "            self.linear = Linear(2 * out_channels, slices)\n",
    "\n",
    "        self._alpha = None\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        glorot(self.weight_node)\n",
    "        glorot(self.weight_edge)\n",
    "        self.bilinear.reset_parameters()\n",
    "        self.linear.reset_parameters()\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None, return_attention_weights=None):\n",
    "\n",
    "        x = torch.matmul(x, self.weight_node)\n",
    "\n",
    "        if self.weight_edge is not None:\n",
    "            assert edge_attr is not None\n",
    "            edge_attr = torch.matmul(edge_attr, self.weight_edge)\n",
    "\n",
    "        out = self.propagate(edge_index, x=x, edge_attr=edge_attr)\n",
    "\n",
    "        alpha = self._alpha\n",
    "        self._alpha = None\n",
    "\n",
    "        if isinstance(return_attention_weights, bool):\n",
    "            assert alpha is not None\n",
    "            return out, (edge_index, alpha)\n",
    "        else:\n",
    "            return out\n",
    "\n",
    "    def message(self, x_i, x_j, edge_attr):\n",
    "        score = self.bilinear(x_i, x_j)\n",
    "        if edge_attr is not None:\n",
    "            vec = torch.cat((x_i, edge_attr, x_j), 1)\n",
    "            block_score = self.linear(vec)  # bias already included\n",
    "        else:\n",
    "            vec = torch.cat((x_i, x_j), 1)\n",
    "            block_score = self.linear(vec)\n",
    "        scores = score + block_score\n",
    "        alpha = torch.tanh(scores)\n",
    "        self._alpha = alpha\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "\n",
    "        dim_split = self.out_channels // self.slices\n",
    "        out = x_j.view(-1, self.slices, dim_split)\n",
    "\n",
    "        out = out * alpha.view(-1, self.slices, 1)\n",
    "        out = out.view(-1, self.out_channels)\n",
    "        return out\n",
    "\n",
    "    def __repr__(self):\n",
    "        return '{}({}, {}, slices={})'.format(self.__class__.__name__,\n",
    "                                              self.in_channels,\n",
    "                                              self.out_channels, self.slices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------\n",
    "# HiGNN backbone\n",
    "# ---------------------------------------\n",
    "class HiGNN(torch.nn.Module):\n",
    "    \"\"\"Hierarchical informative graph neural network for molecular representation.\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, hidden_channels, out_channels, edge_dim, num_layers,\n",
    "                 slices, dropout, f_att=False, r=4, brics=True, cl=False):\n",
    "        super(HiGNN, self).__init__()\n",
    "\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.num_layers = num_layers\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.f_att = f_att\n",
    "        self.brics = brics\n",
    "        self.cl = cl\n",
    "\n",
    "        # atom feature transformation\n",
    "        self.lin_a = Linear(in_channels, hidden_channels)\n",
    "        self.lin_b = Linear(edge_dim, hidden_channels)\n",
    "\n",
    "        # convs block\n",
    "        self.atom_convs = torch.nn.ModuleList()\n",
    "        for _ in range(num_layers):\n",
    "            conv = NTNConv(hidden_channels, hidden_channels, slices=slices,\n",
    "                           dropout=dropout, edge_dim=hidden_channels)\n",
    "            self.atom_convs.append(conv)\n",
    "\n",
    "        self.lin_gate = Linear(3 * hidden_channels, hidden_channels)\n",
    "\n",
    "        if self.f_att:\n",
    "            self.feature_att = FeatureAttention(channels=hidden_channels, reduction=r)\n",
    "\n",
    "        if self.brics:\n",
    "            # mol-fra attention\n",
    "            self.cross_att = GATConv(hidden_channels, hidden_channels, heads=4,\n",
    "                                     dropout=dropout, add_self_loops=False,\n",
    "                                     negative_slope=0.01, concat=False)\n",
    "\n",
    "        if self.brics:\n",
    "            self.out = Linear(2 * hidden_channels, out_channels)\n",
    "        else:\n",
    "            self.out = Linear(hidden_channels, out_channels)\n",
    "\n",
    "        if self.cl:\n",
    "            self.lin_project = Linear(hidden_channels, int(hidden_channels/2))\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "\n",
    "        self.lin_a.reset_parameters()\n",
    "        self.lin_b.reset_parameters()\n",
    "\n",
    "        for conv in self.atom_convs:\n",
    "            conv.reset_parameters()\n",
    "\n",
    "        self.lin_gate.reset_parameters()\n",
    "\n",
    "        if self.f_att:\n",
    "            self.feature_att.reset_parameters()\n",
    "\n",
    "        if self.brics:\n",
    "            self.cross_att.reset_parameters()\n",
    "\n",
    "        self.out.reset_parameters()\n",
    "\n",
    "        if self.cl:\n",
    "            self.lin_project.reset_parameters()\n",
    "\n",
    "    def forward(self, data):\n",
    "        # get mol input\n",
    "        x = data.x\n",
    "        edge_index = data.edge_index\n",
    "        edge_attr = data.edge_attr\n",
    "        batch = data.batch\n",
    "\n",
    "        x = F.relu(self.lin_a(x))  # (N, 46) -> (N, hidden_channels)\n",
    "        edge_attr = F.relu(self.lin_b(edge_attr))  # (N, 10) -> (N, hidden_channels)\n",
    "\n",
    "        fa = []\n",
    "        # mol conv block\n",
    "        for i in range(0, self.num_layers):\n",
    "            h = F.relu(self.atom_convs[i](x, edge_index, edge_attr))\n",
    "            beta = self.lin_gate(torch.cat([x, h, x - h], 1)).sigmoid()\n",
    "            x = beta * x + (1 - beta) * h\n",
    "            if self.f_att:\n",
    "                x, y_ = self.feature_att(x, batch)\n",
    "                fa.append(y_)\n",
    "\n",
    "        mol_vec = global_add_pool(x, batch).relu_()\n",
    "\n",
    "        if self.brics:\n",
    "            # get fragment input\n",
    "            fra_x = data.x\n",
    "            fra_edge_index = data.fra_edge_index\n",
    "            fra_edge_attr = data.fra_edge_attr\n",
    "            cluster = data.cluster_index\n",
    "\n",
    "            fra_x = F.relu(self.lin_a(fra_x))  # (N, 46) -> (N, hidden_channels)\n",
    "            fra_edge_attr = F.leaky_relu_(self.lin_b(fra_edge_attr))  # (N, 10) -> (N, hidden_channels)\n",
    "\n",
    "            # fragment convs block\n",
    "            for i in range(0, self.num_layers):\n",
    "                fra_h = F.relu(self.atom_convs[i](fra_x, fra_edge_index, fra_edge_attr))\n",
    "                beta = self.lin_gate(torch.cat([fra_x, fra_h, fra_x - fra_h], 1)).sigmoid()\n",
    "                fra_x = beta * fra_x + (1 - beta) * fra_h\n",
    "                if self.f_att:\n",
    "                    fra_x, _ = self.feature_att(fra_x, cluster)\n",
    "\n",
    "            fra_x = global_add_pool(fra_x, cluster).relu_()\n",
    "\n",
    "            # get fragment batch\n",
    "            cluster, perm = consecutive_cluster(cluster)\n",
    "            fra_batch = pool_batch(perm, data.batch)\n",
    "\n",
    "            # molecule-fragment attention\n",
    "            row = torch.arange(fra_batch.size(0), device=batch.device)\n",
    "            mol_fra_index = torch.stack([row, fra_batch], dim=0)\n",
    "            fra_vec = self.cross_att((fra_x, mol_vec), mol_fra_index)\n",
    "            fra_vec = fra_vec.relu()\n",
    "\n",
    "            vectors_concat = list()\n",
    "            vectors_concat.append(mol_vec)\n",
    "            vectors_concat.append(fra_vec)\n",
    "\n",
    "            out = torch.cat(vectors_concat, 1)\n",
    "\n",
    "            # molecule-fragment contrastive\n",
    "            if self.cl:\n",
    "                out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "                return self.out(out), self.lin_project(mol_vec).relu_(), self.lin_project(fra_vec).relu_()\n",
    "            else:\n",
    "                out = F.dropout(out, p=self.dropout, training=self.training)\n",
    "                return self.out(out), fa\n",
    "\n",
    "        else:\n",
    "            assert self.cl is False\n",
    "            out = F.dropout(mol_vec, p=self.dropout, training=self.training)\n",
    "            return self.out(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 加载模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_best_result(model):\n",
    "    best_ckpt_path = 'E:/3-Code/Jupternote book/HiGNN_Vis/tox21_best_ckpt.pth'\n",
    "    ckpt = torch.load(best_ckpt_path, map_location=torch.device('cpu'))\n",
    "    model.load_state_dict(ckpt['model'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HiGNN(\n",
      "  (lin_a): Linear(in_features=46, out_features=256, bias=True)\n",
      "  (lin_b): Linear(in_features=10, out_features=256, bias=True)\n",
      "  (atom_convs): ModuleList(\n",
      "    (0): NTNConv(256, 256, slices=2)\n",
      "    (1): NTNConv(256, 256, slices=2)\n",
      "    (2): NTNConv(256, 256, slices=2)\n",
      "  )\n",
      "  (lin_gate): Linear(in_features=768, out_features=256, bias=True)\n",
      "  (feature_att): FeatureAttention(\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=256, out_features=64, bias=False)\n",
      "      (1): ReLU(inplace=True)\n",
      "      (2): Linear(in_features=64, out_features=256, bias=False)\n",
      "    )\n",
      "  )\n",
      "  (cross_att): GATConv(256, 256, heads=4)\n",
      "  (out): Linear(in_features=512, out_features=24, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------\n",
    "# Build HiGNN \n",
    "# ---------------------------------------\n",
    "model = HiGNN(in_channels=46,\n",
    "              hidden_channels=256,\n",
    "              out_channels=24,\n",
    "              edge_dim=10,\n",
    "              num_layers=3,\n",
    "              dropout=0.5,\n",
    "              slices=2,\n",
    "              f_att=True,\n",
    "              r=4,\n",
    "              brics=True,\n",
    "              cl=False)\n",
    "\n",
    "model = load_best_result(model)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 进行预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def get_header(path):\n",
    "    with open(path) as f:\n",
    "        header = next(csv.reader(f))\n",
    "\n",
    "    return header\n",
    "\n",
    "\n",
    "def get_task_names(path, use_compound_names=False):\n",
    "    index = 2 if use_compound_names else 1\n",
    "    task_names = get_header(path)[index:]\n",
    "\n",
    "    return task_names\n",
    "\n",
    "task_names = get_task_names('E:/3-Code/Jupternote book/HiGNN_Vis/raw/tox21.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7831\n"
     ]
    }
   ],
   "source": [
    "path = 'E:/3-Code/Jupternote book/HiGNN_Vis'\n",
    "dataset = 'tox21'\n",
    "task_type = 'classification'\n",
    "tasks = task_names\n",
    "tox21 = MolDataset(root=path, dataset=dataset, task_type=task_type, tasks=tasks)\n",
    "print(len(tox21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "784"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed = 2029\n",
    "random = Random(seed)\n",
    "indices = list(range(len(tox21)))\n",
    "random.seed(seed)\n",
    "random.shuffle(indices)\n",
    "\n",
    "train_size = int(0.8 * len(tox21))\n",
    "val_size = int(0.1 * len(tox21))\n",
    "test_size = len(tox21) - train_size - val_size\n",
    "\n",
    "trn_id, val_id, test_id = indices[:train_size], \\\n",
    "                          indices[train_size:(train_size + val_size)], \\\n",
    "                          indices[(train_size + val_size):]\n",
    "len(test_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "tox21_test = tox21[test_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Batch(batch=[14848], cluster_index=[14848], edge_attr=[30878, 10], edge_index=[2, 30878], fra_edge_attr=[26728, 10], fra_edge_index=[2, 26728], ptr=[785], smiles=[784], x=[14848, 46], y=[784, 12])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loader = DataLoader(tox21_test, batch_size=784)\n",
    "iter_ = iter(loader)\n",
    "batch = next(iter_)\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()  # 关闭dropout\n",
    "output = model(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 1.0534, -0.9555,  1.7339,  ..., -2.6404,  2.5901, -2.7638],\n",
       "         [ 0.9031, -0.9170,  1.1977,  ..., -0.7447,  0.3027, -0.4066],\n",
       "         [-3.2785,  3.7095, -2.5252,  ..., -0.5109,  1.3867, -1.5189],\n",
       "         ...,\n",
       "         [ 0.8243, -0.8440,  0.6335,  ...,  1.4691, -1.6419,  1.4477],\n",
       "         [-0.1385,  0.2545,  1.5754,  ...,  1.5246, -0.5056,  0.4561],\n",
       "         [-3.0913,  3.2826, -2.1624,  ...,  0.3497,  0.1309, -0.6398]],\n",
       "        grad_fn=<AddmmBackward>),\n",
       " [tensor([[0.3651, 0.1889, 0.2367,  ..., 0.3447, 0.4278, 0.3908],\n",
       "          [0.0697, 0.0539, 0.0185,  ..., 0.2967, 0.1847, 0.1615],\n",
       "          [0.0366, 0.0010, 0.0083,  ..., 0.0289, 0.3105, 0.0251],\n",
       "          ...,\n",
       "          [0.0202, 0.0933, 0.0034,  ..., 0.0880, 0.0623, 0.1130],\n",
       "          [0.0848, 0.4221, 0.0122,  ..., 0.2098, 0.1414, 0.2107],\n",
       "          [0.1586, 0.0085, 0.0413,  ..., 0.0190, 0.3240, 0.0879]],\n",
       "         grad_fn=<SigmoidBackward>),\n",
       "  tensor([[0.3221, 0.2468, 0.3001,  ..., 0.3851, 0.3962, 0.4558],\n",
       "          [0.2039, 0.2449, 0.1982,  ..., 0.5176, 0.3347, 0.3741],\n",
       "          [0.0910, 0.0310, 0.2031,  ..., 0.0650, 0.3833, 0.0340],\n",
       "          ...,\n",
       "          [0.0378, 0.5996, 0.0107,  ..., 0.6107, 0.1029, 0.4877],\n",
       "          [0.2904, 0.5256, 0.0573,  ..., 0.5281, 0.2559, 0.2842],\n",
       "          [0.2073, 0.3152, 0.0647,  ..., 0.0493, 0.3610, 0.1006]],\n",
       "         grad_fn=<SigmoidBackward>),\n",
       "  tensor([[0.3529, 0.1748, 0.3074,  ..., 0.3466, 0.3840, 0.4094],\n",
       "          [0.3103, 0.3147, 0.3613,  ..., 0.5429, 0.3880, 0.4388],\n",
       "          [0.9104, 0.0557, 0.2807,  ..., 0.0112, 0.5828, 0.0215],\n",
       "          ...,\n",
       "          [0.0519, 0.3966, 0.0350,  ..., 0.4764, 0.1824, 0.3906],\n",
       "          [0.2906, 0.4100, 0.0939,  ..., 0.4763, 0.3089, 0.2490],\n",
       "          [0.9202, 0.2403, 0.0529,  ..., 0.0131, 0.5191, 0.0315]],\n",
       "         grad_fn=<SigmoidBackward>)])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = output[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = [i.detach().numpy() for i in fa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "fa = [i.mean(0) for i in fa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = pd.DataFrame(fa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out = df_out.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_out.to_csv('tox21_att.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
